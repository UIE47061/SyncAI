from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import httpx
import random, string, time, json, re, os
from typing import Union, List
from .participants_api import ROOMS, topics, votes

router = APIRouter(prefix="/ai", tags=["AI"])

# AnythingLLM API é…ç½®
ANYTHINGLLM_BASE_URL = os.getenv("ANYTHINGLLM_BASE_URL", "http://localhost:3001")
ANYTHINGLLM_API_KEY = os.getenv("ANYTHINGLLM_API_KEY", "PNB2B7R-4EC4P21-NM0XHTX-4BHZBHJ")
ANYTHINGLLM_WORKSPACE_SLUG = os.getenv("ANYTHINGLLM_WORKSPACE_SLUG", "syncai")

if not ANYTHINGLLM_API_KEY:
    print("è­¦å‘Šï¼šæœªè¨­ç½® ANYTHINGLLM_API_KEY ç’°å¢ƒè®Šæ•¸")

# HTTP å®¢æˆ¶ç«¯é…ç½®
httpx_client = httpx.AsyncClient(timeout=60.0)

async def ensure_workspace_exists(workspace_slug: str, workspace_name: str) -> bool:
    """
    ç¢ºä¿æŒ‡å®šçš„å·¥ä½œå€å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡å‰µå»º
    
    Args:
        workspace_slug: å·¥ä½œå€çš„slugï¼ˆé€šå¸¸æ˜¯æœƒè­°å®¤ä»£ç¢¼ï¼‰
        workspace_name: å·¥ä½œå€çš„é¡¯ç¤ºåç¨±ï¼ˆé€šå¸¸æ˜¯æœƒè­°å®¤åç¨±ï¼‰
    
    Returns:
        True if workspace exists or was created successfully
    
    Raises:
        HTTPException: ç•¶æ“ä½œå¤±æ•—æ™‚
    """
    if not ANYTHINGLLM_API_KEY:
        raise HTTPException(status_code=500, detail="æœªé…ç½® AnythingLLM API Key")
    
    headers = {
        "Authorization": f"Bearer {ANYTHINGLLM_API_KEY}",
        "Content-Type": "application/json"
    }
    
    try:
        # 1. æª¢æŸ¥å·¥ä½œå€æ˜¯å¦å·²å­˜åœ¨
        response = await httpx_client.get(
            f"{ANYTHINGLLM_BASE_URL}/api/v1/workspace/{workspace_slug}",
            headers=headers
        )
        
        if response.status_code == 200:
            print(f"å·¥ä½œå€ '{workspace_slug}' å·²å­˜åœ¨")
            return True
        
        # 2. å¦‚æœä¸å­˜åœ¨ï¼Œå‰µå»ºæ–°å·¥ä½œå€
        if response.status_code == 404:
            create_payload = {
                "name": workspace_name,
                "slug": workspace_slug,
                "description": f"SyncAI æœƒè­°å®¤: {workspace_name}"
            }
            
            create_response = await httpx_client.post(
                f"{ANYTHINGLLM_BASE_URL}/api/v1/workspaces",
                headers=headers,
                json=create_payload
            )
            
            if create_response.status_code == 200:
                print(f"æˆåŠŸå‰µå»ºå·¥ä½œå€ '{workspace_slug}' ({workspace_name})")
                return True
            else:
                error_detail = f"å‰µå»ºå·¥ä½œå€å¤±æ•—: {create_response.status_code}"
                try:
                    error_data = create_response.json()
                    error_detail += f" - {error_data.get('message', 'æœªçŸ¥éŒ¯èª¤')}"
                except:
                    pass
                raise HTTPException(status_code=500, detail=error_detail)
        else:
            # å…¶ä»–éŒ¯èª¤
            raise HTTPException(status_code=500, detail=f"æª¢æŸ¥å·¥ä½œå€æ™‚ç™¼ç”ŸéŒ¯èª¤: {response.status_code}")
            
    except httpx.TimeoutException:
        raise HTTPException(status_code=500, detail="AnythingLLM API è«‹æ±‚è¶…æ™‚")
    except httpx.RequestError as e:
        raise HTTPException(status_code=500, detail=f"AnythingLLM API é€£æ¥éŒ¯èª¤: {str(e)}")
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç¢ºä¿å·¥ä½œå€å­˜åœ¨æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {str(e)}")

def get_workspace_info_from_room(room_code: str = None) -> tuple[str, str]:
    """
    å¾æœƒè­°å®¤ä»£ç¢¼ç²å–å·¥ä½œå€ä¿¡æ¯
    
    Args:
        room_code: æœƒè­°å®¤ä»£ç¢¼ï¼Œå¦‚æœç‚ºNoneå‰‡ä½¿ç”¨é è¨­
    
    Returns:
        (workspace_slug, workspace_name)
    """
    # æš«æ™‚ä½¿ç”¨ç¾æœ‰çš„ "mac" å·¥ä½œå€ï¼Œç›´åˆ°æ¨¡å‹é…ç½®å®Œæˆ
    # TODO: åœ¨æ¨¡å‹é…ç½®å¥½å¾Œï¼Œæ”¹ç‚ºæ ¹æ“šæœƒè­°å®¤å‹•æ…‹å‰µå»ºå·¥ä½œå€
    return "mac", "Macå·¥ä½œå€"
    
    # æœªä¾†çš„å‹•æ…‹å·¥ä½œå€é‚è¼¯ï¼ˆç•¶æ¨¡å‹é…ç½®å¥½å¾Œå•Ÿç”¨ï¼‰
    # if room_code and room_code in ROOMS:
    #     room_data = ROOMS[room_code]
    #     room_title = room_data.get('title', f'æœƒè­°å®¤-{room_code}')
    #     workspace_slug = f"syncai-{room_code.lower()}"
    #     workspace_name = f"SyncAI-{room_title}"
    #     return workspace_slug, workspace_name
    # else:
    #     return "syncai-default", "SyncAI-é è¨­æœƒè­°å®¤"

async def call_anythingllm_chat(message: str, workspace_slug: str, mode: str = "chat") -> str:
    """
    èª¿ç”¨ AnythingLLM çš„èŠå¤© API
    
    Args:
        message: è¦ç™¼é€çš„è¨Šæ¯
        workspace_slug: å·¥ä½œå€çš„slug
        mode: èŠå¤©æ¨¡å¼ (chat, query, ç­‰)
    
    Returns:
        AI çš„å›è¦†æ–‡å­—
    
    Raises:
        HTTPException: ç•¶ API èª¿ç”¨å¤±æ•—æ™‚
    """
    if not ANYTHINGLLM_API_KEY:
        raise HTTPException(status_code=500, detail="æœªé…ç½® AnythingLLM API Key")
    
    headers = {
        "Authorization": f"Bearer {ANYTHINGLLM_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "message": message,
        "mode": mode
    }
    
    try:
        response = await httpx_client.post(
            f"{ANYTHINGLLM_BASE_URL}/api/v1/workspace/{workspace_slug}/chat",
            headers=headers,
            json=payload
        )
        
        if response.status_code != 200:
            error_detail = f"AnythingLLM API éŒ¯èª¤: {response.status_code}"
            try:
                error_data = response.json()
                error_detail += f" - {error_data.get('message', 'æœªçŸ¥éŒ¯èª¤')}"
            except:
                pass
            raise HTTPException(status_code=500, detail=error_detail)
        
        result = response.json()
        
        # æå–å›è¦†æ–‡å­—ï¼ˆæ ¹æ“š AnythingLLM çš„å›è¦†æ ¼å¼èª¿æ•´ï¼‰
        print(f"AnythingLLM å›è¦†: {result}")  # èª¿è©¦æ—¥èªŒ
        
        # æª¢æŸ¥æ˜¯å¦æœ‰éŒ¯èª¤
        if "error" in result and result["error"]:
            raise HTTPException(status_code=500, detail=f"AnythingLLM éŒ¯èª¤: {result['error']}")
        
        if "textResponse" in result and result["textResponse"]:
            return result["textResponse"]
        elif "message" in result:
            return result["message"]
        elif "response" in result:
            return result["response"]
        else:
            # å¦‚æœæ‰¾ä¸åˆ°é æœŸçš„æ¬„ä½ï¼Œè¿”å›æ•´å€‹å›è¦†
            return str(result)
            
    except httpx.TimeoutException:
        raise HTTPException(status_code=500, detail="AnythingLLM API è«‹æ±‚è¶…æ™‚")
    except httpx.RequestError as e:
        raise HTTPException(status_code=500, detail=f"AnythingLLM API é€£æ¥éŒ¯èª¤: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"èª¿ç”¨ AnythingLLM API æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {str(e)}")

class AskRequest(BaseModel):
    prompt: str

@router.post("/ask")
async def ask_ai(req: AskRequest):
    try:
        # ä½¿ç”¨é è¨­å·¥ä½œå€
        workspace_slug, workspace_name = get_workspace_info_from_room()
        await ensure_workspace_exists(workspace_slug, workspace_name)
        answer = await call_anythingllm_chat(req.prompt, workspace_slug)
        return {"answer": answer}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI è™•ç†å¤±æ•—: {str(e)}")

# å®šç¾©ç”¨æ–¼ AI ç¸½çµçš„è«‹æ±‚æ¨¡å‹
class SummaryRequest(BaseModel):
    room: str  # æœƒè­°å®¤ä»£ç¢¼
    topic: str # è¦ç¸½çµçš„ä¸»é¡Œ

# --- é‡å¯« summary_ai å‡½å¼ ---
@router.post("/summary")
async def summary_ai(req: SummaryRequest):
    """
    å°æŒ‡å®šæœƒè­°å®¤çš„ç‰¹å®šä¸»é¡Œé€²è¡Œ AI ç¸½çµ

    [POST] /ai/summary

    åƒæ•¸ï¼š
    - room (str): æœƒè­°å®¤ä»£ç¢¼
    - topic (str): è¦é€²è¡Œç¸½çµçš„ä¸»é¡Œåç¨±

    å›å‚³ï¼š
    - summary (str): AI ç”Ÿæˆçš„ç¸½çµæ–‡å­—
    """
    # æª¢æŸ¥æœƒè­°å®¤æ˜¯å¦å­˜åœ¨
    if req.room not in ROOMS:
        return {"summary": "éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„æœƒè­°å®¤ã€‚"}

    # çµ„åˆä¸»é¡Œ ID ä¸¦æª¢æŸ¥ä¸»é¡Œæ˜¯å¦å­˜åœ¨
    topic_id = f"{req.room}_{req.topic}"
    if topic_id not in topics:
        return {"summary": "éŒ¯èª¤ï¼šåœ¨è©²æœƒè­°å®¤ä¸­æ‰¾ä¸åˆ°æŒ‡å®šçš„ä¸»é¡Œã€‚"}

    room_data = ROOMS[req.room]
    topic_data = topics[topic_id]
    
    # --- é–‹å§‹å»ºç«‹ Prompt ---
    prompt = f"ä¸»é¡Œ: {req.topic}\n"

    # å–å¾—åƒèˆ‡è€…åˆ—è¡¨
    participants = [p.get("nickname", "åŒ¿å") for p in room_data.get("participants_list", [])]
    if participants:
        prompt += f"åƒèˆ‡è€…: {', '.join(participants)}\n"

    prompt += "\nç•™è¨€èˆ‡ç¥¨æ•¸:\n"

    # å–å¾—è©²ä¸»é¡Œçš„æ‰€æœ‰ç•™è¨€èˆ‡å…¶å°æ‡‰çš„ç¥¨æ•¸
    comments_for_prompt = []
    if "comments" in topic_data:
        for c in topic_data["comments"]:
            comment_id = c.get("id")
            nickname = c.get("nickname", "åŒ¿å")
            content = c.get("content", "")
            
            # å¾ votes å­—å…¸ä¸­å–å¾—ç¥¨æ•¸
            good_votes = len(votes.get(comment_id, {}).get("good", []))
            bad_votes = len(votes.get(comment_id, {}).get("bad", []))

            comments_for_prompt.append(
                f"- {nickname}ï¼š{content}ï¼ˆğŸ‘{good_votes}ã€ğŸ‘{bad_votes}ï¼‰"
            )

    if not comments_for_prompt:
        prompt += "ç›®å‰é€™å€‹ä¸»é¡Œé‚„æ²’æœ‰ä»»ä½•ç•™è¨€ã€‚\n"
    else:
        prompt += "\n".join(comments_for_prompt)

    # åŠ ä¸Šå›ºå®šçš„æŒ‡ä»¤æ¨¡æ¿
    prompt += """

                    ä½ çš„ä»»å‹™æ˜¯æ“”ä»»ä¸€å€‹å°ˆæ¥­çš„æœƒè­°è¨˜éŒ„å“¡ã€‚
                    ä½ å¿…é ˆåš´æ ¼æ ¹æ“šä¸Šæ–¹æä¾›çš„ã€Œç•™è¨€èˆ‡ç¥¨æ•¸ã€è³‡è¨Šï¼Œé€²è¡Œæ¢åˆ—å¼å½™æ•´ã€‚
                    ç¦æ­¢è‡†æ¸¬æˆ–ç”Ÿæˆä»»ä½•æœªåœ¨è³‡æ–™ä¸­å‡ºç¾çš„æ•¸å­—ã€åç¨±æˆ–è§€é»ã€‚
                    ä½ çš„å›ç­”å…§å®¹ï¼Œåªèƒ½åŒ…å«å½™æ•´å¾Œçš„çµæœï¼Œç¦æ­¢åŠ å…¥ä»»ä½•é–‹å ´ç™½ã€å•å€™èªæˆ–çµå°¾çš„å…è²¬è²æ˜ã€‚

                    è«‹ç›´æ¥ä»¥ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼Œä¸¦å°‡çœŸå¯¦çš„å…§å®¹å¡«å…¥ï¼š
                    ---
                    1. [ç¬¬ä¸€å€‹é‡é»ä¸»é¡Œ]
                    - ä¸»æµæ„è¦‹ï¼š
                    - åˆ†æ­§é»ï¼šï¼ˆè‹¥ç„¡å‰‡å¯«â€œç„¡â€ï¼‰
                    - å¯èƒ½æ±ºè­°ï¼š
                    ---
                    2. [ç¬¬äºŒå€‹é‡é»ä¸»é¡Œ]
                    - ä¸»æµæ„è¦‹ï¼š
                    - åˆ†æ­§é»ï¼šï¼ˆè‹¥ç„¡å‰‡å¯«â€œç„¡â€ï¼‰
                    - å¯èƒ½æ±ºè­°ï¼š
                    ---
                    ç¸½çµï¼š
                    [æ­¤è™•æ¢åˆ—æœƒè­°çš„æœ€é‡è¦å…±è­˜æˆ–å¾ŒçºŒè¿½è¹¤äº‹é …]
                """

    # å‘¼å« AnythingLLM API
    try:
        # ä½¿ç”¨æœƒè­°å®¤ç‰¹å®šçš„å·¥ä½œå€
        workspace_slug, workspace_name = get_workspace_info_from_room(req.room)
        await ensure_workspace_exists(workspace_slug, workspace_name)
        summary_text = await call_anythingllm_chat(prompt, workspace_slug, mode="query")
        return {"summary": summary_text}
    except HTTPException:
        raise
    except Exception as e:
        return {"summary": f"AI ç¸½çµç”Ÿæˆå¤±æ•—: {str(e)}"}

async def _generate_topics_from_title(meeting_title: str, topic_count: int, workspace_slug: str) -> List[str]:
    """
    æ ¹æ“šæœƒè­°æ¨™é¡Œç”Ÿæˆä¸»é¡Œçš„æ ¸å¿ƒé‚è¼¯ã€‚
    é€™æ˜¯ä¸€å€‹å…§éƒ¨å‡½å¼ï¼Œæ—¨åœ¨è¢«å…¶ä»– API ç«¯é»èª¿ç”¨ã€‚
    """
    topic_count = max(1, min(10, topic_count))
    meeting_title = meeting_title.strip()

    if not meeting_title:
        return ["éŒ¯èª¤ï¼šæœƒè­°åç¨±ä¸å¯ç‚ºç©ºã€‚"]

    prompt = f"""
        ä½ çš„ä»»å‹™æ˜¯ä¸€ä½å°ˆæ¥­ä¸”é«˜æ•ˆçš„æœƒè­°ä¸»æŒäººã€‚
        è«‹æ ¹æ“šä»¥ä¸‹æä¾›çš„ã€Œæœƒè­°åç¨±ã€ï¼Œç‚ºé€™æ¬¡æœƒè­°è…¦åŠ›æ¿€ç›ªå‡º {topic_count} å€‹æœ€é—œéµã€æœ€ç›¸é—œçš„è¨è«–è­°ç¨‹ä¸»é¡Œã€‚

        æœƒè­°åç¨±ï¼š"{meeting_title}"

        ä½ çš„å›è¦†å¿…é ˆæ˜¯ä¸€å€‹å–®å±¤çš„ JSON æ ¼å¼é™£åˆ— (a flat JSON array)ï¼Œé™£åˆ—ä¸­åªåŒ…å«ç°¡æ½”ä¸”éç©ºçš„ä¸»é¡Œå­—ä¸²ã€‚
        ç¦æ­¢åœ¨é™£åˆ—ä¸­åŒ…å«ä»»ä½•ç©ºå­—ä¸² ("")ã€å·¢ç‹€é™£åˆ—æˆ–å­—ä¸²åŒ–çš„ JSONã€‚
        è«‹ä¸è¦åŒ…å«ä»»ä½•æ•¸å­—ç·¨è™Ÿã€ç ´æŠ˜è™Ÿã€æˆ–ä»»ä½•å…¶ä»–çš„é–‹å ´ç™½èˆ‡è§£é‡‹ã€‚

        æ­£ç¢ºç¯„ä¾‹ï¼š
        ["å›é¡§ç¬¬äºŒå­£éŠ·å”®æ•¸æ“š", "è¨è«–æ–°åŠŸèƒ½å„ªå…ˆç´š", "è¨­å®šç¬¬ä¸‰å­£KPI"]

        éŒ¯èª¤ç¯„ä¾‹ï¼š
        ["", "ä¸»é¡ŒA", "[\"ä¸»é¡ŒB\", \"ä¸»é¡ŒC\"]"]
    """

    try:
        raw_text = await call_anythingllm_chat(prompt, workspace_slug, mode="query")

        # --- 4. è§£æ AI çš„å›è¦† (v4 çµ‚æ¥µç‰ˆ) ---
        
        # éè¿´å‡½å¼ï¼Œç”¨æ–¼æ”¤å¹³æ‰€æœ‰å¯èƒ½çš„å·¢ç‹€çµæ§‹
        def flatten_and_clean_topics(items):
            if not isinstance(items, list):
                return []
            
            flat_list = []
            for item in items:
                # å¦‚æœé …ç›®æ˜¯åˆ—è¡¨ï¼Œéè¿´æ”¤å¹³
                if isinstance(item, list):
                    flat_list.extend(flatten_and_clean_topics(item))
                # å¦‚æœé …ç›®æ˜¯å­—ä¸²
                elif isinstance(item, str):
                    # å»é™¤é ­å°¾ç©ºç™½
                    item = item.strip()
                    # å˜—è©¦å°‡å…¶è¦–ç‚º JSON é€²è¡Œè§£æ
                    if item.startswith('[') and item.endswith(']'):
                        try:
                            nested_list = json.loads(item)
                            flat_list.extend(flatten_and_clean_topics(nested_list))
                        except json.JSONDecodeError:
                            # è§£æå¤±æ•—ï¼Œç•¶ä½œæ™®é€šå­—ä¸²ï¼Œä½†éæ¿¾ç©ºå€¼
                            if item:
                                flat_list.append(item)
                    # å¦‚æœæ˜¯æ™®é€šå­—ä¸²ï¼Œéæ¿¾ç©ºå€¼
                    elif item:
                        flat_list.append(item)
            return flat_list

        try:
            # æ­¥é©Ÿ 1: ç§»é™¤æ½›åœ¨çš„ Markdown ç¨‹å¼ç¢¼å€å¡Šæ¨™ç±¤
            cleaned_text = re.sub(r'```(json)?\s*', '', raw_text)
            cleaned_text = cleaned_text.strip('`').strip()

            # æ­¥é©Ÿ 2: æ‰¾åˆ°æœ€å¤–å±¤çš„ []
            start_index = cleaned_text.find('[')
            end_index = cleaned_text.rfind(']') + 1
            
            if start_index != -1 and end_index != 0:
                json_str = cleaned_text[start_index:end_index]
                initial_topics = json.loads(json_str)
            else:
                # å¦‚æœæ‰¾ä¸åˆ° JSON çµæ§‹ï¼Œç›´æ¥æŒ‰è¡Œåˆ†å‰²
                raise ValueError("æ‰¾ä¸åˆ° JSON é™£åˆ—çµæ§‹")

            # æ­¥é©Ÿ 3: ä½¿ç”¨éè¿´å‡½å¼é€²è¡Œå¾¹åº•çš„æ”¤å¹³èˆ‡æ¸…ç†
            generated_topics = flatten_and_clean_topics(initial_topics)

        except (json.JSONDecodeError, ValueError):
            # æ­¥é©Ÿ 4: å¦‚æœ JSON è§£æå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ (æŒ‰è¡Œåˆ†å‰²)
            cleaned_text = re.sub(r'```(json)?\s*', '', raw_text)
            cleaned_text = cleaned_text.strip('`').strip()
            generated_topics = [
                line.strip().lstrip('-*').lstrip('123456789.').strip()
                for line in cleaned_text.split('\n')
                if line.strip() and line.strip() not in ['[', ']']
            ]
        
        # --- 5. æœ€å¾Œçš„æ¸…ç†èˆ‡æ•¸é‡æ§åˆ¶ ---
        final_topics = [topic for topic in generated_topics if topic]
        return final_topics[:topic_count]

    except Exception as e:
        print(f"Error calling LLM for topic generation: {e}")
        return [f"æŠ±æ­‰ï¼ŒAI æœå‹™æš«æ™‚ç„¡æ³•é€£ç·šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"]


class GenerateTopicsRequest(BaseModel):
    """ç”¨æ–¼ AI ç”Ÿæˆä¸»é¡Œè«‹æ±‚çš„æ¨¡å‹"""
    meeting_title: str
    topic_count: int

@router.post("/generate_topics")
async def generate_ai_topics(req: GenerateTopicsRequest):
    """
    æ ¹æ“šæœƒè­°åç¨±å’ŒæŒ‡å®šæ•¸é‡ï¼Œä½¿ç”¨ AI ç”Ÿæˆè­°ç¨‹ä¸»é¡Œã€‚

    [POST] /ai/generate_topics

    åƒæ•¸ï¼š
    - meeting_title (str): æœƒè­°çš„æ¨™é¡Œæˆ–ä¸»è¦ç›®çš„ã€‚
    - topic_count (int): å¸Œæœ›ç”Ÿæˆçš„ä¸»é¡Œæ•¸é‡ã€‚

    å›å‚³ï¼š
    - topics (list[str]): ä¸€å€‹åŒ…å« AI ç”Ÿæˆçš„ä¸»é¡Œå­—ä¸²çš„åˆ—è¡¨ã€‚
    """
    # --- 1. åŸºæœ¬é©—è­‰ ---
    # ç¢ºä¿ä¸»é¡Œæ•¸é‡åœ¨ä¸€å€‹åˆç†çš„ç¯„åœå…§
    topic_count = max(1, min(10, req.topic_count)) 
    meeting_title = req.meeting_title.strip()

    if not meeting_title:
        return {"topics": ["éŒ¯èª¤ï¼šæœƒè­°åç¨±ä¸å¯ç‚ºç©ºã€‚"]}

    # --- 2. è¨­è¨ˆ Prompt (æŒ‡ä»¤) ---
    # é€™æ˜¯èˆ‡ AI æºé€šçš„é—œéµï¼Œæˆ‘å€‘çµ¦äºˆå®ƒè§’è‰²ã€ä»»å‹™å’Œæ˜ç¢ºçš„è¼¸å‡ºæ ¼å¼è¦æ±‚ã€‚
    prompt = f"""
        ä½ çš„ä»»å‹™æ˜¯ä¸€ä½å°ˆæ¥­ä¸”é«˜æ•ˆçš„æœƒè­°ä¸»æŒäººã€‚
        è«‹æ ¹æ“šä»¥ä¸‹æä¾›çš„ã€Œæœƒè­°åç¨±ã€ï¼Œç‚ºé€™æ¬¡æœƒè­°è…¦åŠ›æ¿€ç›ªå‡º {topic_count} å€‹æœ€é—œéµã€æœ€ç›¸é—œçš„è¨è«–è­°ç¨‹ä¸»é¡Œï¼Œä¸¦ä½¿ç”¨ç¹é«”ä¸­æ–‡å›è¦†ï¼

        æœƒè­°åç¨±ï¼š"{meeting_title}"

        ä½ çš„å›è¦†å¿…é ˆæ˜¯ä¸€å€‹ JSON æ ¼å¼çš„é™£åˆ— (array)ï¼Œé™£åˆ—ä¸­åªåŒ…å«ä¸»é¡Œçš„å­—ä¸²ã€‚
        è«‹ä¸è¦åŒ…å«ä»»ä½•æ•¸å­—ç·¨è™Ÿã€ç ´æŠ˜è™Ÿã€æˆ–ä»»ä½•å…¶ä»–çš„é–‹å ´ç™½èˆ‡è§£é‡‹ã€‚

        ä¾‹å¦‚ï¼Œå¦‚æœæœƒè­°åç¨±æ˜¯ã€Œ2025å¹´ç¬¬ä¸‰å­£ç”¢å“é–‹ç™¼ç­–ç•¥æœƒè­°ã€ï¼Œä¸¦ä¸”ä¸»é¡Œæ•¸é‡æ˜¯3çš„è©±ï¼Œä½ æ‡‰è©²å›å‚³ï¼š
        ["å›é¡§ç¬¬äºŒå­£éŠ·å”®æ•¸æ“šèˆ‡å®¢æˆ¶å›é¥‹", "è¨è«–æ–°åŠŸèƒ½å„ªå…ˆç´šèˆ‡é–‹ç™¼æ™‚ç¨‹", "è¨­å®šç¬¬ä¸‰å­£çš„é—œéµç¸¾æ•ˆæŒ‡æ¨™ (KPI)"]
    """

    # --- 3. å‘¼å« AnythingLLM API ---
    try:
        # ä½¿ç”¨é è¨­å·¥ä½œå€é€²è¡Œä¸»é¡Œç”Ÿæˆ
        workspace_slug, workspace_name = get_workspace_info_from_room()
        await ensure_workspace_exists(workspace_slug, workspace_name)
        raw_text = await call_anythingllm_chat(prompt, workspace_slug, mode="query")

        # --- 4. è§£æ AI çš„å›è¦† ---
        # æˆ‘å€‘å„ªå…ˆå˜—è©¦å°‡å›è¦†ç›´æ¥è§£æç‚º JSON
        try:
            # æ‰¾åˆ° JSON é™£åˆ—çš„é–‹å§‹å’ŒçµæŸä½ç½®ï¼Œä»¥æ‡‰å° AI å¯èƒ½åŠ å…¥å¤šé¤˜æ–‡å­—çš„æƒ…æ³
            start_index = raw_text.find('[')
            end_index = raw_text.rfind(']') + 1
            if start_index != -1 and end_index != 0:
                json_str = raw_text[start_index:end_index]
                generated_topics = json.loads(json_str)
                # ç¢ºä¿çµæœæ˜¯ä¸€å€‹åˆ—è¡¨
                if not isinstance(generated_topics, list):
                    raise ValueError("AI å›å‚³çš„ä¸æ˜¯ä¸€å€‹åˆ—è¡¨")
            else:
                 raise ValueError("åœ¨ AI å›æ‡‰ä¸­æ‰¾ä¸åˆ° JSON é™£åˆ—")

        except (json.JSONDecodeError, ValueError):
            # å¦‚æœ JSON è§£æå¤±æ•—ï¼Œæˆ‘å€‘é€€ä¸€æ­¥ï¼Œå˜—è©¦æŒ‰è¡Œåˆ†å‰²ä½œç‚ºå‚™ç”¨æ–¹æ¡ˆ
            # é€™èƒ½æ‡‰å° AI æœªå®Œå…¨éµå¾ªæ ¼å¼è¦æ±‚çš„æƒ…æ³
            generated_topics = [
                line.strip().lstrip('-').lstrip('*').lstrip('123456789.').strip() 
                for line in raw_text.split('\n') 
                if line.strip()
            ]
            # åªå–å›æˆ‘å€‘éœ€è¦çš„æ•¸é‡
            generated_topics = generated_topics[:topic_count]

        return {"topics": generated_topics}

    except Exception as e:
        # è™•ç†å‘¼å« AI æ™‚å¯èƒ½ç™¼ç”Ÿçš„ä»»ä½•éŒ¯èª¤
        print(f"Error calling LLM for topic generation: {e}")
        return {"topics": [f"æŠ±æ­‰ï¼ŒAI æœå‹™æš«æ™‚ç„¡æ³•é€£ç·šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"]}

# æ–°å¢çš„è«‹æ±‚æ¨¡å‹ï¼Œç”¨æ–¼ generate_single_topic ç«¯é»
class GenerateSingleTopicRequest(BaseModel):
    room: str
    custom_prompt: str

@router.post("/generate_single_topic")
async def generate_single_topic(req: GenerateSingleTopicRequest):
    """
    æ ¹æ“šæœƒè­°å®¤å’Œè‡ªè¨‚æç¤ºï¼Œä½¿ç”¨ AI ç”Ÿæˆå–®ä¸€è­°ç¨‹ä¸»é¡Œã€‚

    [POST] /ai/generate_single_topic

    åƒæ•¸ï¼š
    - room (str): æœƒè­°å®¤ä»£ç¢¼
    - custom_prompt (str): è‡ªè¨‚çš„æç¤ºèªå¥ï¼Œç”¨æ–¼å¼•å° AI ç”Ÿæˆä¸»é¡Œ

    å›å‚³ï¼š
    - topic (str): AI ç”Ÿæˆçš„ä¸»é¡Œå­—ä¸²
    """
    # æª¢æŸ¥æœƒè­°å®¤æ˜¯å¦å­˜åœ¨
    if req.room not in ROOMS:
        return {"topic": "éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„æœƒè­°å®¤ã€‚"}

    room_data = ROOMS[req.room]

    # --- é–‹å§‹å»ºç«‹ Prompt ---
    prompt = f"æœƒè­°åç¨±: {room_data.get('title', 'æœªå‘½åæœƒè­°')}\n"
    prompt += f"æœƒè­°ä»£ç¢¼: {req.room}\n"
    
    # æ·»åŠ æœƒè­°æè¿°/æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰
    if room_data.get('topic_summary'):
        prompt += f"æœƒè­°æ‘˜è¦: {room_data['topic_summary']}\n"
    if room_data.get('desired_outcome'):
        prompt += f"é æœŸæˆæœ: {room_data['desired_outcome']}\n"
    
    # å–å¾—åƒèˆ‡è€…åˆ—è¡¨
    participants = [p.get("nickname", "åŒ¿å") for p in room_data.get("participants_list", [])]
    if participants:
        prompt += f"åƒèˆ‡è€…: {', '.join(participants)}\n"
    
    # æ‰¾å‡ºè©²æœƒè­°å®¤çš„æ‰€æœ‰å·²æœ‰ä¸»é¡Œ
    existing_topics = [
        t["topic_name"] for t_id, t in topics.items() 
        if t["room_id"] == req.room and "topic_name" in t
    ]
    
    if existing_topics:
        prompt += "\nå·²æœ‰çš„ä¸»é¡Œ:\n"
        for i, topic_name in enumerate(existing_topics, 1):
            prompt += f"{i}. {topic_name}\n"
        
        prompt += "\nè«‹ç”Ÿæˆä¸€å€‹èˆ‡å·²æœ‰ä¸»é¡Œäº’è£œä½†ä¸é‡è¤‡çš„æ–°è­°ç¨‹ä¸»é¡Œã€‚ä¸»é¡Œæ‡‰è©²æ—¢è¦èˆ‡æœƒè­°æ•´é«”ç›®æ¨™ç›¸é—œï¼Œåˆèƒ½å¤ è¦†è“‹å°šæœªè¨è«–çš„é‡è¦æ–¹é¢ã€‚"
    else:
        prompt += "\nç›®å‰æœƒè­°å°šæœªæœ‰ä»»ä½•ä¸»é¡Œã€‚è«‹ç”Ÿæˆä¸€å€‹é©åˆä½œç‚ºç¬¬ä¸€å€‹è¨è«–ä¸»é¡Œçš„è­°ç¨‹ã€‚"

    # åŠ ä¸Šä½¿ç”¨è€…è‡ªè¨‚çš„æç¤º
    if req.custom_prompt:
        prompt += f"\n\nè‡ªè¨‚æç¤º: {req.custom_prompt}"
    
    prompt += "\n\nè«‹ç›´æ¥è¿”å›ä¸€å€‹ç°¡æ½”ã€å…·é«”ä¸”ä¸è¶…é10å€‹å­—çš„ä¸»é¡Œï¼Œä¸éœ€è¦ä»»ä½•å‰ç¶´æˆ–è§£é‡‹ã€‚"

    # å‘¼å« AnythingLLM API
    try:
        # ä½¿ç”¨æœƒè­°å®¤ç‰¹å®šçš„å·¥ä½œå€
        workspace_slug, workspace_name = get_workspace_info_from_room(req.room)
        await ensure_workspace_exists(workspace_slug, workspace_name)
        topic = await call_anythingllm_chat(prompt, workspace_slug, mode="query")
        return {"topic": topic.strip()}
    except HTTPException:
        raise
    except Exception as e:
        return {"topic": f"AI ä¸»é¡Œç”Ÿæˆå¤±æ•—: {str(e)}"}